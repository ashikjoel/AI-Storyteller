# -*- coding: utf-8 -*-
"""AI story teller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XIYfsj6gl2Wlh_uobQJ1aT6JwMlYiFsZ

day:1
google ai studio for api key
"""

# Commented out IPython magic to ensure Python compatibility.
# @title
# %env GEMINI_API_KEY=AIzaSyAMczrM55eo9ZE43PRgPCCLFwNzpH5AyJI

!pip install -q transformers pillow google-generativeai

from google import genai
import os
client = genai.Client()

if "GEMINI_API_KEY" not in os.environ:
  print("please set your gemini api key in the environment variable")
else:
  client=genai.Client()
  MODEL="gemini-2.5-flash"

prompt=input("enter your story prompt and press enter:\n")
if prompt.strip()=="":
  print("no prompt entered , exiting.")
else:
  print(f"generating story for prompt:{prompt}")
  print("it may take few seconds")
  try:
    resp=client.models.generate_content(model=MODEL,contents=[prompt])
    print("\n------generated story-----\n")
    print(resp.text)
  except Exception as e:
    print(f"error occurred while generating story: {e}")

"""day 2"""

!pip install -q transformers pillow google-generativeai timm

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
from google import genai
import os
import io

if "GEMINI_API_KEY" not in os.environ:
  print("please set your gemini api key in the environment variable")
else:
  client=genai.Client()
  MODEL="gemini-2.5-flash"

processor=BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model=BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

from google.colab import files
uploaded=files.upload()

for fn in uploaded.keys():
  image=Image.open(fn).convert('RGB')
  display(image)

inputs=processor(image,return_tensors='pt')
out=model.generate(**inputs)

caption=processor.decode(out[0],
skip_special_tokens=True)

print("Caption gerated by BLIP:")
print(caption)

story_prompt=(f"Write a short story(around 500-700 words)based on this scene description:\n{caption}")
print(story_prompt)

print("sending this to gemini. \n")

response=client.models.generate_content(model=MODEL,contents=story_prompt)
story =response.text
print("story generated by gemini:")
print(story)

with open("generated_story.txt","w") as f:
  f.write(story)
from google.colab import files
files.download("generated_story.txt")

"""day 3"""

!pip install -q ipywidgets

from google.colab import files
from PIL import Image
import io

uploaded=files.upload()

images=[]
image_names=[]

for name,file in uploaded.items():
  image=Image.open(io.BytesIO(file)).convert('RGB')
  image_names.append(name)
  images.append(image)

  display(image)

from transformers import BlipProcessor, BlipForConditionalGeneration


processor=BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
blip_model=BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

captions=[]

for imp in images:
  inputs = processor(imp, return_tensors="pt")
  out = blip_model.generate(**inputs,max_new_tokens=30)
  caption = processor.decode(out[0], skip_special_tokens=True)
  captions.append(caption)

print("Caption gerated from images:")
for i,caption in enumerate(captions):
  print(f"{image_names[i]}: {caption}")
print(captions)

import ipywidgets as widgets
from IPython.display import display, clear_output

tone_dropdown=widgets.Dropdown(
    options=["whimsical","adventures","suspenseful","romantic","Sci-fic","mystery"],
    value="Sci-fic",
    description="Tone:",
    disabled=False
)

length_dropdown=widgets.Dropdown(
    options=["Short(100-200 words)",
             "Medium(300-500 words)",
             "Long(600-800 words)"],
    value="Medium(300-500 words)",
    description="Length:",

)

generate_button=widgets.Button(description="Generate Story")
output_box=widgets.Output()

display(tone_dropdown,length_dropdown,generate_button,output_box)

def on_generate_clicked(b):
    with output_box:
        clear_output()

        tone = tone_dropdown.value
        length_map = {
            "Short(100-200 words)": "100-200 words",
            "Medium(300-500 words)": "300-500 words",
            "Long(600-800 words)": "600-800 words"
        }
        length = length_map[length_dropdown.value]

        # Fix 1: Proper assignment
        caption_prompt = "\n".join([f"- {c}" for c in captions])

        outline_prompt = (
            f"Using the following scene descriptions, create a 3-chapter story outline. "
            f"Each chapter should have a title and a short summary.\n\n"
            f"{caption_prompt}\n\nOutline:"
        )

        try:
            # Fix 2: consistent variable names
            outline_response = client.models.generate_content(
                model=MODEL,
                contents=outline_prompt
            )
            outline = outline_response.text  # Or outline_response.output_text depending on SDK

            print("Story outline:\n")
            print(outline)

            full_story = ""
            for i in range(1, 4):
                chapter_prompt = (
                    f"Using the outline below, write Chapter {i} in a {tone} tone. "
                    f"Make it {length}. Add vivid details, good pacing, and consistent characters.\n\n"
                    f"Outline:\n{outline}\n\nChapter {i}:"
                )

                chapter_response = client.models.generate_content(
                    model=MODEL,
                    contents=chapter_prompt
                )
                chapter_text = chapter_response.text  # Or .output_text

                print(f"\nChapter {i}:\n")
                print(chapter_text)

                full_story += f"Chapter {i}:\n{chapter_text}\n\n"

            # Save story
            with open("multi_image_story.txt", "w") as f:
                f.write(full_story)
            print("\nStory saved as multi_image_story.txt")

            from google.colab import files
            files.download("multi_image_story.txt")

        except Exception as e:
            print(f"Error occurred while generating story: {e}")


generate_button.on_click(on_generate_clicked)

"""day 4"""

!pip install -q gtts reportlab

story_text= """
Chapter 1:
The air in the forgotten service tunnel hummed with the residual energy of ancient, deactivated conduits, a faint static scent clinging to the dust motes dancing in the infrequent shafts of light. Here, in the chill shadow of a derelict grav-lift, a diverse cadre of felines had assembled. They weren’t drawn by a dropped morsel or a territorial skirmish, but by something far more profound: a low-frequency psychic resonance, a whisper of bio-engineered directive buried deep within their genetic code. They sat in a solemn, almost ritualistic semicircle, their fur ranging from the sleek obsidian of a void-dweller descendant to the mottled calico of a former companionship unit, each pair of eyes fixed on the oldest amongst them.

Kaelen, a grizzled Maine Coon whose massive form bore the scars of countless urban cycles, stretched a gnarled paw. Her purr, a deep rumble that vibrated through the very floor plating, wasn't one of contentment but of a data-stream initiating. “The ancient algorithms stir,” she rasped, her voice a low static against the tunnel’s quiet. “The fragmented memory-packets coalesce.” She spoke not of simple tales, but of sub-neural echoes, ghost images of a time before the Great Silence, before their ancestors became mere domesticated bio-companions.

She spoke of the Sun King. Not a physical monarch, but an entity, a golden-maned being of light and authority, whose domain stretched further than the highest sky-scraper. She wove a tapestry of ancestral data: sun-drenched plains, a wild freedom that felt alien to their sheltered existences, a lost home untamed by human constructs. Each recounted fragment, each echo of a bygone world, triggered dormant neural pathways, igniting a primal yearning.

Among them, Luna, a young tabby with fur the color of rust-stained chrome, felt the resonance most acutely. Her tail twitched, a nervous tremor, as Kaelen’s words painted visions of vast, open spaces – a stark contrast to their confined urban sector. Her own bio-signature surged with an unfamiliar heat, a hunger for the unknown. The Sun King, the untamed home, it wasn't just old data to her; it felt like a destination, a profound mission she was only just beginning to understand. A current of restless energy coursed through the gathered cats, a collective awakening of something forgotten, yet vital, pushing them toward a destiny encoded millennia ago.

Chapter 2:
The elder’s fragmented tales had been potent, but for Luna, they were merely the prelude. Every night, as the domestic world slept, her consciousness transcended the soft blankets and the purring silence. She didn’t dream; she *witnessed*. The visions were more than mere dreams; they were neural imprints, ancient data streams woven into the very fabric of her feline consciousness.

She saw him with breathtaking clarity: the Sun King. Not just a cat, but a colossal, golden-maned lion, his fur shimmering with an ethereal luminescence that defied the laws of physics. He stood regal and still upon a towering, obsidian monolith, his immense form silhouetted against a sky painted in hues of impossible dawn. His gaze, a knowing, ancient amber, swept across an endless, untamed domain – a landscape that pulsed with a vibrant, primeval energy. The vision came with a unique vibrational resonance, a sub-etheric hum that resonated deep in her bones, a call as undeniable as gravity. This was no fanciful myth; it was a deeply embedded genetic imperative, a psionic echo of a forgotten era.

The pull became a constant hum beneath her every waking thought, a navigational beacon burning brighter than any star. The comfortable routine of the human-kept house felt stifling, an artificial construct that caged her burgeoning wild spirit. She had to answer.

Under the cloak of a moonless night, Luna made her preparations. She didn't have to vocalize her intent; the urgency of her quest, the ancient whisper in her soul, resonated with others. Orion, a sleek, shadow-pelted tomcat whose pragmatic gaze missed nothing, and Lyra, a calico queen whose cautious nature belied a fierce, ancestral loyalty, quietly joined her. They understood. Their eyes, glinting in the dim light, reflected a similar, though perhaps less vivid, spark of ancestral memory.

Their departure was a silent, fluid motion through the backyard’s forgotten gate, a breach of the invisible barrier between the known and the unknown. Every rustle of leaves, every distant urban hum, felt alien and magnified. The domestic scents of home rapidly faded, replaced by the wild, earthy tang of unseen flora and the faint, metallic scent of the sprawling human infrastructure they would have to navigate. The towering monolith, the golden Sun King, became their guiding star, a constant, low-frequency pulse in Luna's mind, directing their path with an instinct more precise than any map. They were not merely walking; they were following a signal, a bio-luminescent thread spun through the tapestry of time, leading them towards a destination hinted at in the deepest recesses of their untamed, forgotten lineage.

Chapter 3:
The arid scent of dust finally gave way to a sharp, mineral tang. Luna, her paws raw and her fur matted from days of relentless travel, crested the final dune, her companions a panting line behind her. Below them, not the expected overgrown ruins or a verdant lost kingdom, but an expanse of shifting sand meeting a vast, indifferent azure. The coast. The air vibrated with a low, primal hum – the ocean’s roar, a sound entirely alien yet resonating deep within their bone marrow.

The sun, a colossal molten orb, was already sinking, bleeding incandescent oranges and purples across the boundless horizon. It was a spectacle of such raw, untamed energy that it silenced even the chattering gulls. As they descended onto the cool, damp sand, the ground beneath their paws pulsed with the rhythmic impact of colossal waves. Each crash was a percussive announcement, a declaration of power that dwarfed any vision of a stone throne or a golden-maned monarch.

Then, it struck Luna with the force of an electron surge. The whispers, the elder’s fractured tales, her own vivid dreams of the "Sun King" standing regally on a towering rock – they weren’t literal coordinates to a forgotten palace. This wasn't about reclaiming a physical dominion. The sun, blazing farewell, painted the ocean not as a barrier, but as an endless mirror reflecting the true nature of their quest.

The “Sun King” wasn’t a ruler, but a state of being. The lost kingdom wasn't a territory, but the wild, untethered spirit encoded in their ancestral DNA. This vast, roaring beach, where the ancient echoes of their lineage met the infinite rhythm of the waves, was their sanctuary. Here, under the watchful descent of their solar archetype, Luna felt a profound re-calibration, a re-writing of their domestic programming. Her companions, eyes wide and pupils dilated, seemed to sense it too. They stretched, no longer with weariness, but with a newfound, primal grace. This wasn't the end of a journey; it was the genesis of a species rediscovering its true heritage, its profound freedom, and its rightful belonging on the wild, elemental stage of the world.
"""

from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas

def export_pdf(text, filename="story.pdf"):
    c = canvas.Canvas(filename, pagesize=letter)
    width, height = letter
    text_object = c.beginText(40, height - 40)
    text_object.setFont("Helvetica", 12)

    # Add text line by line (wrapping at 90 chars)
    for line in text.split('\n'):
        for subline in [line[i:i+90] for i in range(0, len(line), 90)]:
            text_object.textLine(subline)

    c.drawText(text_object)
    c.save()


export_pdf(story_text)

from google.colab import files
files.download("story.pdf")

from gtts import gTTS
from IPython.display import Audio,display
from google.colab import files

voices = {
    "Default English (US Female)": {"lang": "en", "tld": "com"},
    "British Accent": {"lang": "en", "tld": "co.uk"},
    "Australian Accent": {"lang": "en", "tld": "com.au"},
    "Indian Accent": {"lang": "en", "tld": "co.in"},
    "Slow Reading Voice": {"lang": "en", "tld": "com", "slow": True}
}

for label,options in voices.items():
  print(f"Generating Audio:{label}")

  tts=gTTS(text=story_text,
           lang=options["lang"],
           slow=options.get("slow", False),
           tld=options.get("tld", "com"))

  filename=f"{label.replace(' ','_')}.mp3"

  tts.save(filename)

  display(Audio(filename,autoplay=False))

  files.download(filename)

"""day 5"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_streamlit_story.py
# import streamlit as st
# from PIL import Image
# import io, requests, os
# import textwrap
# from gtts import gTTS
# from transformers import BlipProcessor, BlipForConditionalGeneration
# from reportlab.pdfgen import canvas
# from reportlab.lib.pagesizes import A4
# from reportlab.lib.utils import ImageReader
# from pyngrok import ngrok
# import tempfile
# import google.generativeai as genai
# import torch
# 
# # authentication
# NGROK_AUTH_TOKEN = "33T4LJ4Xrz30sSIKK6EYPLWsq7y_paq6HYf7p4g2eHoH65st"
# BACKGROUND_IMAGE_URL = "https://i.postimg.cc/SxDHQ1Xp/lion.jpg"
# GEMINI_API_KEY = "AIzaSyAMczrM55eo9ZE43PRgPCCLFwNzpH5AyJI"
# 
# st.set_page_config(page_title="StoryTeller", layout="wide")
# 
# # streamlit page setup
# st.markdown(
#    f"""
#    <style>
#    .stApp {{
#        background-image: url("{BACKGROUND_IMAGE_URL}");
#        background-size: cover;
#        background-attachment: fixed;
#    }}
#    section[data-testid="stSidebar"] {{
#        background: rgba(0,0,0,0.3);
#        backdrop-filter: blur(10px);
#        border-radius: 12px;
#        padding: 10px;
#    }}
#    div[data-testid="stFileUploader"] {{
#        background: rgba(255,255,255,0.2);
#        border-radius: 10px;
#        padding: 10px;
#    }}
#    html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, li, input, textarea {{
#        color: #93A8AC !important;
#    }}
#    .stButton>button, .stDownloadButton>button {{
#        color: #93A8AC !important;
#        border-color: #93A8AC;
#    }}
#    </style>
#    """,
#    unsafe_allow_html=True
# )
# 
# st.title("Multi-Image AI Storyteller")
# st.markdown("Upload images → Generate story → Export as PDF & MP3")
# 
# with st.sidebar:
#    tone = st.selectbox("Tone", ["Adventurous", "Whimsical", "Romantic", "Mysterious", "Humorous", "Calm"])
#    length_label = st.selectbox("Length", ["Short (200-300 words)", "Medium (300-600 words)", "Long (600-1000 words)"])
#    start_ngrok = st.checkbox("Start ngrok tunnel")
#    if start_ngrok:
#        ngrok.set_auth_token(NGROK_AUTH_TOKEN)
#        if "ngrok_url" not in st.session_state:
#            st.session_state["ngrok_url"] = ngrok.connect(8501)
#        st.success(f"Public URL: {st.session_state['ngrok_url']}")
# 
# uploaded_images = st.file_uploader("Upload multiple images", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
# 
# # caption model
# @st.cache_resource
# def load_models():
#    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
#    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large").to("cuda" if torch.cuda.is_available() else "cpu")
#    return processor, model
# 
# processor, blip_model = load_models()
# 
# # config gemini
# genai.configure(api_key=GEMINI_API_KEY)
# 
# @st.cache_resource
# def load_gemini_model():
#    return genai.GenerativeModel(model_name="models/gemini-2.5-flash")
# 
# gemini_model = load_gemini_model()
# 
# # captioning the images
# def get_captions(images):
#     captions = []
#     for img in images:
#         if img.mode != "RGB":
#             img = img.convert("RGB")
#         inputs = processor(images=img, return_tensors="pt").to(blip_model.device)
#         out = blip_model.generate(**inputs)
#         caption = processor.decode(out[0], skip_special_tokens=True)
#         captions.append(caption)
#     return captions
# 
# def generate_story(captions, tone, length_label):
#    length_map = {
#        "Short (200-300 words)": (200, 300, 800),
#        "Medium (300-600 words)": (300, 600, 1200),
#        "Long (600-1000 words)": (600, 1000, 1600)
#    }
#    min_words, max_words, max_tokens = length_map.get(length_label, (300, 600, 1200))
# 
#    prompt = (
#        f"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\n\n"
#        + "\n".join([f"- {cap}" for cap in captions])
#        + f"\n\nThe story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle, and end."
#        + f"\nMake it approximately between {min_words} and {max_words} words long."
#    )
# 
#    try:
#        response = gemini_model.generate_content(
#            contents=prompt,
#            generation_config=genai.GenerationConfig(
#                temperature=0.9,
#                top_p=0.95,
#                max_output_tokens=max_tokens
#            )
#        )
#        return response.text.strip()
#    except Exception as e:
#        return f"❌ Error generating story: {e}"
# 
# def create_pdf(story_text, images):
#     buffer = io.BytesIO()
#     c = canvas.Canvas(buffer, pagesize=A4)
#     w, h = A4
# 
#     try:
#         bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert("RGB")
#         bg = ImageReader(bg_img)
#         c.drawImage(bg, 0, 0, width=w, height=h)
#     except:
#         pass
# 
#     c.setFont("Helvetica-Bold", 16)
#     c.drawString(50, h - 50, "Generated Story")
# 
#     text = textwrap.wrap(story_text, 100)
#     y = h - 80
#     for line in text:
#         if y < 80:
#             c.showPage()
#             y = h - 80
#         c.drawString(50, y, line)
#         y -= 15
# 
#     if images:
#         c.showPage()
#         c.setFont("Helvetica-Bold", 16)
#         c.drawString(50, h - 50, "Uploaded Images")
#         x, y = 50, h - 150
#         for img in images:
#             img.thumbnail((200, 200))
#             c.drawImage(ImageReader(img), x, y, width=img.width, height=img.height)
#             x += 220
#             if x > w - 200:
#                 x = 50
#                 y -= 220
# 
#     c.save()
#     buffer.seek(0)
#     return buffer
# 
# def create_audio(story):
#     audio_bytes = io.BytesIO()
#     tts = gTTS(story)
#     tts.write_to_fp(audio_bytes)
#     audio_bytes.seek(0)
#     return audio_bytes
# 
# # main logic
# if st.button("Generate Story") and uploaded_images:
#    pil_images = [Image.open(img) for img in uploaded_images]
# 
#    with st.spinner("Generating captions..."):
#        captions = get_captions(pil_images)
#        for i, cap in enumerate(captions):
#            st.write(f"**Image {i+1}**: {cap}")
# 
#    with st.spinner("Generating story..."):
#        story = generate_story(captions, tone, length_label)
#        st.success("Story generated!")
#        st.write(story)
# 
#    with st.spinner("Creating PDF..."):
#        pdf_file = create_pdf(story, pil_images)
#        st.download_button("📄 Download Story as PDF", data=pdf_file, file_name="story.pdf", mime="application/pdf")
# 
#    with st.spinner("Creating Audio..."):
#        audio = create_audio(story)
#        st.audio(audio)
#        st.download_button("🔊 Download Story as MP3", data=audio, file_name="story.mp3", mime="audio/mpeg")
# 
# elif not uploaded_images:
#    st.warning("Upload at least one image to begin.")
#

!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow


!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &


from pyngrok import ngrok
ngrok.set_auth_token("33T4LJ4Xrz30sSIKK6EYPLWsq7y_paq6HYf7p4g2eHoH65st")
url = ngrok.connect(8501)
print("Public URL:", url)